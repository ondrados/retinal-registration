{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GRS-kmkDLPzp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import colors\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UloL86RtLUjB",
        "outputId": "4827647d-7c9c-41cb-e945-d77460177cf3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/siamese-registration')\n",
        "\n",
        "from datasets import FolderFramesDataset\n",
        "from models import *\n",
        "from utils import get_transformation_matrix"
      ],
      "metadata": {
        "id": "xBYaO3NMLWCI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/data\"\n",
        "output_path = \"/content/drive/MyDrive/outputs\""
      ],
      "metadata": {
        "id": "T6KtXnUlLXwa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = FolderFramesDataset(\n",
        "    transforms=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    path=os.path.join(path, \"frame_sequences\"),\n",
        ")"
      ],
      "metadata": {
        "id": "CHLuoEs-QSCC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=2, shuffle=False)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "cTfdoevQQ6Ty"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"model-9.pt\"\n",
        "model = siamese_resnet18(1, 7)\n",
        "model.load_state_dict(torch.load(os.path.join(output_path, checkpoint), map_location=device))\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "print(f\"Running on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYYgq1D5RALT",
        "outputId": "e1ef1134-ddf8-4b54-91a8-fdf78d573cfd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_list = []\n",
        "image_list_warped = []\n",
        "\n",
        "with tqdm(test_loader) as validation_progress:\n",
        "    for img0, img1 in validation_progress:\n",
        "        \n",
        "\n",
        "        if len(image_list) == 0:\n",
        "            img0, img1 = img0.to(device=device), img1.to(device=device)\n",
        "            outputs = model(img0, img1)\n",
        "            image0 = img0.detach().cpu().numpy()[0, 0, :, :]\n",
        "            image1 = img1.detach().cpu().numpy()[0, 0, :, :]\n",
        "\n",
        "        else:\n",
        "            img1 = img1.to(device=device)\n",
        "            img3 = img0\n",
        "            img3[0, 0, :, :] = torch.from_numpy(image_list_warped[-1])\n",
        "            img3 = img3.to(device=device)\n",
        "            outputs = model(img3, img1)\n",
        "            image0 = img3.detach().cpu().numpy()[0, 0, :, :]\n",
        "            image1 = img1.detach().cpu().numpy()[0, 0, :, :]\n",
        "        \n",
        "        rows, cols = image0.shape\n",
        "        center = (cols//2, rows//2)\n",
        "        tx, ty, sx, sy, shx, shy, q = outputs.detach().cpu().numpy().reshape(-1).tolist()\n",
        "        matrix = get_transformation_matrix(center, tx, ty, sx, sy, shx, shy, q)\n",
        "        matrix_opencv = np.float32(matrix.flatten()[:6].reshape(2, 3))\n",
        "        inverse_matrix = cv2.invertAffineTransform(matrix_opencv)\n",
        "        warped_image = cv2.warpAffine(image1, inverse_matrix, (cols, rows))\n",
        "\n",
        "        if len(image_list) == 0:\n",
        "            image_list.append(image0)\n",
        "            image_list_warped.append(image1)\n",
        "        else:\n",
        "            image_list.append(image0)\n",
        "            image_list_warped.append(warped_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiFcCjxhSAkA",
        "outputId": "e251caa2-8439-4c96-da86-b44c6f34b574"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 251/251 [00:11<00:00, 21.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.concatenate((image_list[0], image_list_warped[0]), axis = 1)\n",
        "\n",
        "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "out = cv2.VideoWriter('/content/drive/MyDrive/outputs/video/outpy2.mp4', cv2.VideoWriter_fourcc(*'XVID'), 15, (1500, 500), 0)\n",
        "\n",
        "for image, image_warped in zip(image_list, image_list_warped):\n",
        "    img = np.concatenate((image, image_warped), axis = 1)\n",
        "    I = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "    out.write(I)\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "LRb9-68wWVoK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bFUhJlBHctx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}