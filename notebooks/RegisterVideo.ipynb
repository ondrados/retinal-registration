{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VYpOqeQv97rh"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from matplotlib import colors\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5z_GoVK-DJK",
    "outputId": "60d9d7f7-2ef1-4e98-be3f-294023e68bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xl4h8SEh-FeH"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/siamese-registration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K2hyMJKTAgkW"
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils import get_transformation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXmebxauADkT",
    "outputId": "b7cea30c-2594-4c4e-b17c-a98e726fac81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"01/model-9.pt\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = siamese_resnet18(1, 7)\n",
    "model.load_state_dict(torch.load(os.path.join(\"/content/drive/MyDrive/outputs/models\", checkpoint), map_location=device))\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cp7HamGiAhFk",
    "outputId": "2577c0c4-12d3-4e92-ce9f-1ff46c5f9a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames:  253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [00:14<00:00, 17.43 frames/s]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"/content/drive/MyDrive/data/Study_02_00008_02_R.avi\")\n",
    "# Find the number of frames\n",
    "video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "count = 0\n",
    "# Start converting the video\n",
    "image_list = []\n",
    "image_list_warped = []\n",
    "time_start = time.time()\n",
    "with tqdm(total=video_length, unit=' frames') as pbar:\n",
    "    while cap.isOpened():\n",
    "        # Extract the frame\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if not ret:\n",
    "            continue\n",
    "        if len(image_list) == 0:\n",
    "            image_list.append(frame)\n",
    "            image_list_warped.append(frame)\n",
    "        else:\n",
    "            frame0 = image_list_warped[count-1]\n",
    "            frame1 = frame\n",
    "\n",
    "            img0 = torch.unsqueeze(transforms.functional.to_tensor(frame0), 1).to(device)\n",
    "            img1 = torch.unsqueeze(transforms.functional.to_tensor(frame1), 1).to(device)\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            outputs = model(img0, img1)\n",
    "            end = time.perf_counter()\n",
    "            #print(f\"{count}, time: {end - start}\")\n",
    "\n",
    "            rows, cols = frame0.shape\n",
    "            center = (cols//2, rows//2)\n",
    "            tx, ty, sx, sy, shx, shy, q = outputs.detach().cpu().numpy().reshape(-1).tolist()\n",
    "            matrix = get_transformation_matrix(center, tx, ty, sx, sy, shx, shy, q)\n",
    "            matrix_opencv = np.float32(matrix.flatten()[:6].reshape(2, 3))\n",
    "            inverse_matrix = cv2.invertAffineTransform(matrix_opencv)\n",
    "\n",
    "            frame1_warped = cv2.warpAffine(frame1, inverse_matrix, (cols, rows))\n",
    "\n",
    "            image_list.append(frame)\n",
    "            image_list_warped.append(frame1_warped)\n",
    "\n",
    "        \n",
    "        count = count + 1\n",
    "        pbar.update(1)\n",
    "        # If there are no more frames left\n",
    "        if (count > (video_length-1)):\n",
    "            # Log the time again\n",
    "            time_end = time.time()\n",
    "            # Release the feed\n",
    "            cap.release()\n",
    "            # Print stats\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "x4iILq4yGMY-"
   },
   "outputs": [],
   "source": [
    "img = np.concatenate((image_list[0], image_list_warped[0]), axis = 1)\n",
    "\n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "out = cv2.VideoWriter('/content/drive/MyDrive/outputs/video/Study_02_00008_02_R.mp4', cv2.VideoWriter_fourcc(*'XVID'), 15, (img.shape[1], img.shape[0]), 0)\n",
    "\n",
    "for image, image_warped in zip(image_list, image_list_warped):\n",
    "    img = np.concatenate((image, image_warped), axis = 1)\n",
    "    I = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    out.write(I)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qm2Q7qzGj3i",
    "outputId": "6e777bda-f372-4f3d-89a3-dea36b896523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770, 2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULczAJX-MPxw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Pipeline2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
